{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43ee3e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "import re\n",
    "import random\n",
    "from collections import Counter, defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4e2c85",
   "metadata": {},
   "source": [
    "### Step 1:\n",
    "Set up the combined dataset of video/audio/text clips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e940bd51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paths ready.\n"
     ]
    }
   ],
   "source": [
    "RAW_ROOT   = \"data/raw\"               # your 14 game folders (each contains processed/)\n",
    "FINAL_ROOT = \"data/full_processed\"    # new unified dataset folder\n",
    "\n",
    "# Create final folders\n",
    "os.makedirs(f\"{FINAL_ROOT}/video\", exist_ok=True)\n",
    "os.makedirs(f\"{FINAL_ROOT}/audio\", exist_ok=True)\n",
    "os.makedirs(f\"{FINAL_ROOT}/text\",  exist_ok=True)\n",
    "\n",
    "print(\"Paths ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3f80b6",
   "metadata": {},
   "source": [
    "### Step 2:\n",
    "Normalize and save clip names to be unqiue per game (old: clip_000 -> new: game_half_clip_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc9fcb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_game_name(raw):\n",
    "    \"\"\"\n",
    "    Convert messy game folder names into clean, machine-friendly IDs like:\n",
    "    20160207_1900_Chelsea_1_1_Manchester_United\n",
    "    \"\"\"\n",
    "    raw = raw.strip()\n",
    "    raw = raw.replace(\" - \", \"_\")       # convert separators\n",
    "    raw = re.sub(r'\\s+', '_', raw)      # replace spaces with _\n",
    "    raw = re.sub(r'[^A-Za-z0-9_]', '', raw)  # remove weird chars\n",
    "\n",
    "    return raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20902f80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2016-02-07 - 19-00 Chelsea 1 - 1 Manchester United': '20160207_1900_Chelsea_1_1_Manchester_United',\n",
       " '2016-02-13 - 20-30 Chelsea 5 - 1 Newcastle Utd': '20160213_2030_Chelsea_5_1_Newcastle_Utd',\n",
       " '2016-02-14 - 19-15 Manchester City 1 - 2 Tottenham': '20160214_1915_Manchester_City_1_2_Tottenham',\n",
       " '2016-02-27 - 18-00 Southampton 1 - 2 Chelsea': '20160227_1800_Southampton_1_2_Chelsea',\n",
       " '2016-03-01 - 22-45 Norwich 1 - 2 Chelsea': '20160301_2245_Norwich_1_2_Chelsea',\n",
       " '2016-03-02 - 23-00 Liverpool 3 - 0 Manchester City': '20160302_2300_Liverpool_3_0_Manchester_City',\n",
       " '2016-03-05 - 18-00 Chelsea 1 - 1 Stoke City': '20160305_1800_Chelsea_1_1_Stoke_City',\n",
       " '2016-03-05 - 18-00 Manchester City 4 - 0 Aston Villa': '20160305_1800_Manchester_City_4_0_Aston_Villa',\n",
       " '2016-03-19 - 18-00 Chelsea 2 - 2 West Ham': '20160319_1800_Chelsea_2_2_West_Ham',\n",
       " '2016-03-20 - 19-00 Manchester City 0 - 1 Manchester United': '20160320_1900_Manchester_City_0_1_Manchester_United',\n",
       " '2016-04-09 - 17-00 Swansea 1 - 0 Chelsea': '20160409_1700_Swansea_1_0_Chelsea',\n",
       " '2016-04-23 - 17-00 Bournemouth 1 - 4 Chelsea': '20160423_1700_Bournemouth_1_4_Chelsea',\n",
       " '2016-05-07 - 17-00 Sunderland 3 - 2 Chelsea': '20160507_1700_Sunderland_3_2_Chelsea'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list games in deterministic order\n",
    "game_folders = sorted([\n",
    "    f for f in os.listdir(RAW_ROOT)\n",
    "    if os.path.isdir(os.path.join(RAW_ROOT, f))\n",
    "])\n",
    "\n",
    "# Assign GAME01â€“GAME##\n",
    "game_id_map = { g: normalize_game_name(g) for g in game_folders }\n",
    "\n",
    "game_id_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c77b64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_base_name(game_id, half_id, idx):\n",
    "    return f\"{game_id}_half{half_id}_clip_{idx:04d}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7f8cbb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 20160207_1900_Chelsea_1_1_Manchester_United  |  716 clips\n",
      "Processing 20160213_2030_Chelsea_5_1_Newcastle_Utd  |  677 clips\n",
      "Processing 20160214_1915_Manchester_City_1_2_Tottenham  |  684 clips\n",
      "Processing 20160227_1800_Southampton_1_2_Chelsea  |  700 clips\n",
      "Processing 20160301_2245_Norwich_1_2_Chelsea  |  689 clips\n",
      "Processing 20160302_2300_Liverpool_3_0_Manchester_City  |  676 clips\n",
      "Processing 20160305_1800_Chelsea_1_1_Stoke_City  |  685 clips\n",
      "Processing 20160305_1800_Manchester_City_4_0_Aston_Villa  |  682 clips\n",
      "Processing 20160319_1800_Chelsea_2_2_West_Ham  |  714 clips\n",
      "Processing 20160320_1900_Manchester_City_0_1_Manchester_United  |  676 clips\n",
      "Processing 20160409_1700_Swansea_1_0_Chelsea  |  676 clips\n",
      "Processing 20160423_1700_Bournemouth_1_4_Chelsea  |  686 clips\n",
      "Processing 20160507_1700_Sunderland_3_2_Chelsea  |  743 clips\n"
     ]
    }
   ],
   "source": [
    "master_metadata = []\n",
    "\n",
    "for game_name in game_folders:\n",
    "    game_id = game_id_map[game_name]\n",
    "    game_dir = os.path.join(RAW_ROOT, game_name)\n",
    "\n",
    "    per_game_meta_path = os.path.join(game_dir, \"processed\", \"clips.json\")\n",
    "\n",
    "    with open(per_game_meta_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        clips = json.load(f)\n",
    "\n",
    "    print(f\"Processing {game_id}  |  {len(clips)} clips\")\n",
    "\n",
    "    # iterate with loop index\n",
    "    for idx, clip in enumerate(clips):\n",
    "        half = clip[\"half\"]\n",
    "        base = build_base_name(game_id, half, idx)\n",
    "\n",
    "        # old paths\n",
    "        old_video = clip[\"video_only_path\"]\n",
    "        old_audio = clip[\"audio_path\"]\n",
    "        old_text  = clip[\"transcript_path\"]\n",
    "\n",
    "        # new paths\n",
    "        new_video = f\"{FINAL_ROOT}/video/{base}.mkv\"\n",
    "        new_audio = f\"{FINAL_ROOT}/audio/{base}.wav\"\n",
    "        new_text  = f\"{FINAL_ROOT}/text/{base}.txt\"\n",
    "\n",
    "        # copy\n",
    "        if os.path.exists(old_video): shutil.copy(old_video, new_video)\n",
    "        if os.path.exists(old_audio): shutil.copy(old_audio, new_audio)\n",
    "        if os.path.exists(old_text):  shutil.copy(old_text,  new_text)\n",
    "\n",
    "        # build new metadata record\n",
    "        master_metadata.append({\n",
    "            \"game_id\": game_id,\n",
    "            \"original_game_name\": game_name,\n",
    "            \"clip_name\": base,\n",
    "            \"half\": half,\n",
    "            \"start_ms\": clip[\"start_ms\"],\n",
    "            \"end_ms\": clip[\"end_ms\"],\n",
    "            \"highlight\": clip[\"highlight\"],\n",
    "\n",
    "            # new paths\n",
    "            \"video\": new_video,\n",
    "            \"audio\": new_audio,\n",
    "            \"text\": new_text,\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5c897d",
   "metadata": {},
   "source": [
    "Save the new combined clips.json with al metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e9bc8a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: data/full_processed/clips.json\n",
      "Total clips: 9004\n"
     ]
    }
   ],
   "source": [
    "final_json = f\"{FINAL_ROOT}/clips.json\"\n",
    "\n",
    "with open(final_json, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(master_metadata, f, indent=2)\n",
    "\n",
    "print(\"Saved:\", final_json)\n",
    "print(\"Total clips:\", len(master_metadata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1f4937f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"game_id\": \"20160301_2245_Norwich_1_2_Chelsea\",\n",
      "  \"original_game_name\": \"2016-03-01 - 22-45 Norwich 1 - 2 Chelsea\",\n",
      "  \"clip_name\": \"20160301_2245_Norwich_1_2_Chelsea_half2_clip_0357\",\n",
      "  \"half\": 2,\n",
      "  \"start_ms\": 48000,\n",
      "  \"end_ms\": 56000,\n",
      "  \"highlight\": 0,\n",
      "  \"video\": \"data/full_processed/video/20160301_2245_Norwich_1_2_Chelsea_half2_clip_0357.mkv\",\n",
      "  \"audio\": \"data/full_processed/audio/20160301_2245_Norwich_1_2_Chelsea_half2_clip_0357.wav\",\n",
      "  \"text\": \"data/full_processed/text/20160301_2245_Norwich_1_2_Chelsea_half2_clip_0357.txt\"\n",
      "}\n",
      "True True True\n"
     ]
    }
   ],
   "source": [
    "# sanity check: sample a few records\n",
    "sample = random.choice(master_metadata)\n",
    "print(json.dumps(sample, indent=2))\n",
    "print(os.path.exists(sample[\"video\"]),\n",
    "      os.path.exists(sample[\"audio\"]),\n",
    "      os.path.exists(sample[\"text\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd0ec8c",
   "metadata": {},
   "source": [
    "### Step 3:\n",
    "Find current class imbalance ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c0620bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total clips: 9004\n",
      "Non-Highlights (0): 8701\n",
      "Highlights (1): 303\n",
      "\n",
      "Percentage breakdown:\n",
      "Non-highlights: 96.63%\n",
      "Highlights:     3.37%\n",
      "\n",
      "Imbalance ratio (neg : pos):\n",
      "28.72 : 1\n"
     ]
    }
   ],
   "source": [
    "# Load metadata\n",
    "with open(final_json, \"r\", encoding=\"utf-8\") as f:\n",
    "    clips = json.load(f)\n",
    "\n",
    "# Count highlights (1) and non-highlights (0)\n",
    "labels = [c[\"highlight\"] for c in clips]\n",
    "counter = Counter(labels)\n",
    "\n",
    "num_neg = counter.get(0, 0)\n",
    "num_pos = counter.get(1, 0)\n",
    "total   = num_neg + num_pos\n",
    "\n",
    "print(\"Total clips:\", total)\n",
    "print(\"Non-Highlights (0):\", num_neg)\n",
    "print(\"Highlights (1):\", num_pos)\n",
    "\n",
    "print(\"\\nPercentage breakdown:\")\n",
    "print(f\"Non-highlights: {num_neg/total*100:.2f}%\")\n",
    "print(f\"Highlights:     {num_pos/total*100:.2f}%\")\n",
    "\n",
    "print(\"\\nImbalance ratio (neg : pos):\")\n",
    "if num_pos > 0:\n",
    "    print(f\"{num_neg / num_pos:.2f} : 1\")\n",
    "else:\n",
    "    print(\"No positive clips at all.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b1473b",
   "metadata": {},
   "source": [
    "Randomly downsample to 4:1 neg:pos ratio and save paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf885ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original ratio: 28.716171617161717 : 1\n",
      "New totals:\n",
      "Positives: 303\n",
      "Negatives: 1212\n",
      "Ratio: 4.0 : 1\n",
      "\n",
      "Saved balanced dataset to clips_balanced.json\n"
     ]
    }
   ],
   "source": [
    "FINAL_ROOT = \"data/full_processed\"\n",
    "final_json = f\"{FINAL_ROOT}/clips.json\"\n",
    "\n",
    "with open(final_json, \"r\", encoding=\"utf-8\") as f:\n",
    "    clips = json.load(f)\n",
    "\n",
    "# Separate positives and negatives\n",
    "positives = [c for c in clips if c[\"highlight\"] == 1]\n",
    "negatives = [c for c in clips if c[\"highlight\"] == 0]\n",
    "\n",
    "num_pos = len(positives)\n",
    "num_neg = len(negatives)\n",
    "\n",
    "print(\"Original ratio:\", num_neg/num_pos, \": 1\")\n",
    "\n",
    "# Target ratio = 4:1\n",
    "target_neg = 4 * num_pos\n",
    "\n",
    "# Downsample negatives\n",
    "negatives_downsampled = random.sample(negatives, target_neg)\n",
    "\n",
    "balanced_clips = positives + negatives_downsampled\n",
    "random.shuffle(balanced_clips)\n",
    "\n",
    "print(\"New totals:\")\n",
    "print(\"Positives:\", len(positives))\n",
    "print(\"Negatives:\", len(negatives_downsampled))\n",
    "print(\"Ratio:\", len(negatives_downsampled)/len(positives), \": 1\")\n",
    "\n",
    "# Save to new balanced metadata\n",
    "with open(f\"{FINAL_ROOT}/clips_balanced.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(balanced_clips, f, indent=2)\n",
    "\n",
    "print(\"\\nSaved balanced dataset to clips_balanced.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa42c23d",
   "metadata": {},
   "source": [
    "### Step 4:\n",
    "Set up train/val/test directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "adffd86c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total clips: 1515\n"
     ]
    }
   ],
   "source": [
    "FULL_ROOT = \"data/full_processed\"\n",
    "with open(f\"{FULL_ROOT}/clips_balanced.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    clips = json.load(f)\n",
    "\n",
    "print(\"Total clips:\", len(clips))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bbe39be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT_ROOT = \"data/final\"\n",
    "\n",
    "splits = [\"train\", \"val\", \"test\"]\n",
    "\n",
    "for s in splits:\n",
    "    for sub in [\"video\", \"audio\", \"text\"]:\n",
    "        os.makedirs(f\"{SPLIT_ROOT}/{s}/{sub}\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4d0616",
   "metadata": {},
   "source": [
    "### Step 5:\n",
    "Find splits by game_id - not randomly\n",
    "\n",
    "(we dont want to train on clips from some game such that there will be no clips from that same game when testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c24175a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total games: 13\n"
     ]
    }
   ],
   "source": [
    "clips_by_game = defaultdict(list)\n",
    "\n",
    "for c in clips:\n",
    "    clips_by_game[c[\"game_id\"]].append(c)\n",
    "\n",
    "games = sorted(clips_by_game.keys())\n",
    "print(\"Total games:\", len(games))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8da53a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 9\n",
      "Val: 2\n",
      "Test: 2\n"
     ]
    }
   ],
   "source": [
    "random.seed(42)\n",
    "\n",
    "random.shuffle(games)\n",
    "\n",
    "num_games = len(games)\n",
    "train_end = int(0.7 * num_games)\n",
    "val_end   = int(0.85 * num_games)\n",
    "\n",
    "train_games = games[:train_end]\n",
    "val_games   = games[train_end:val_end]\n",
    "test_games  = games[val_end:]\n",
    "\n",
    "print(\"Train:\", len(train_games))\n",
    "print(\"Val:\", len(val_games))\n",
    "print(\"Test:\", len(test_games))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c09470f",
   "metadata": {},
   "source": [
    "### Step 6:\n",
    "Copy over the split clips into train/val/test and save metadata for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c2dbbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_clip(clip, split_name):\n",
    "    base = clip[\"clip_name\"]  # consistent base name\n",
    "\n",
    "    # Source paths\n",
    "    src_video = clip[\"video\"]\n",
    "    src_audio = clip[\"audio\"]\n",
    "    src_text  = clip[\"text\"]\n",
    "\n",
    "    # Dest paths\n",
    "    dst_video = f\"{SPLIT_ROOT}/{split_name}/video/{base}.mkv\"\n",
    "    dst_audio = f\"{SPLIT_ROOT}/{split_name}/audio/{base}.wav\"\n",
    "    dst_text  = f\"{SPLIT_ROOT}/{split_name}/text/{base}.txt\"\n",
    "\n",
    "    # Copy files\n",
    "    shutil.copy(src_video, dst_video)\n",
    "    shutil.copy(src_audio, dst_audio)\n",
    "    shutil.copy(src_text,  dst_text)\n",
    "\n",
    "    # Return updated metadata\n",
    "    new_clip = dict(clip)\n",
    "    new_clip[\"video\"] = dst_video\n",
    "    new_clip[\"audio\"] = dst_audio\n",
    "    new_clip[\"text\"]  = dst_text\n",
    "    return new_clip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94feef7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train clips: 1072\n",
      "Val clips: 233\n",
      "Test clips: 210\n"
     ]
    }
   ],
   "source": [
    "train_meta, val_meta, test_meta = [], [], []\n",
    "\n",
    "for game in train_games:\n",
    "    for clip in clips_by_game[game]:\n",
    "        train_meta.append(copy_clip(clip, \"train\"))\n",
    "\n",
    "for game in val_games:\n",
    "    for clip in clips_by_game[game]:\n",
    "        val_meta.append(copy_clip(clip, \"val\"))\n",
    "\n",
    "for game in test_games:\n",
    "    for clip in clips_by_game[game]:\n",
    "        test_meta.append(copy_clip(clip, \"test\"))\n",
    "\n",
    "print(\"Train clips:\", len(train_meta))\n",
    "print(\"Val clips:\", len(val_meta))\n",
    "print(\"Test clips:\", len(test_meta))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1e14b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata written successfully.\n"
     ]
    }
   ],
   "source": [
    "with open(f\"{SPLIT_ROOT}/train/clips.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(train_meta, f, indent=2)\n",
    "\n",
    "with open(f\"{SPLIT_ROOT}/val/clips.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(val_meta, f, indent=2)\n",
    "\n",
    "with open(f\"{SPLIT_ROOT}/test/clips.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(test_meta, f, indent=2)\n",
    "\n",
    "print(\"Metadata written successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
