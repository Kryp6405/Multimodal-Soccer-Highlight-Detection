{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7572a824",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import shutil\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6a06d687",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = Path(os.getcwd()).joinpath(\"data\")\n",
    "final_folders = [base_path / \"final_1\", base_path / \"final_2\", base_path / \"final_3\"]\n",
    "output_path = base_path / \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9633ccef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created output directory structure\n"
     ]
    }
   ],
   "source": [
    "# Create output directories\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    split_path = output_path / split\n",
    "    split_path.mkdir(parents=True, exist_ok=True)\n",
    "    for modality in [\"audio\", \"video\", \"text\"]:\n",
    "        (split_path / modality).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Created output directory structure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3db091a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing final_1/train/clips.json\n",
      "Processing final_2/train/clips.json\n",
      "Processing final_2/train/clips.json\n",
      "Processing final_3/train/clips.json\n",
      "Processing final_3/train/clips.json\n",
      "Combined train: 3113 clips\n",
      "Processing final_1/val/clips.json\n",
      "Combined train: 3113 clips\n",
      "Processing final_1/val/clips.json\n",
      "Processing final_2/val/clips.json\n",
      "Processing final_2/val/clips.json\n",
      "Processing final_3/val/clips.json\n",
      "Processing final_3/val/clips.json\n",
      "Combined val: 664 clips\n",
      "Processing final_1/test/clips.json\n",
      "Combined val: 664 clips\n",
      "Processing final_1/test/clips.json\n",
      "Processing final_2/test/clips.json\n",
      "Processing final_2/test/clips.json\n",
      "Processing final_3/test/clips.json\n",
      "Processing final_3/test/clips.json\n",
      "Combined test: 778 clips\n",
      "\n",
      "Done! Combined data saved to data/\n",
      "Combined test: 778 clips\n",
      "\n",
      "Done! Combined data saved to data/\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Combine data\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    combined_clips = []\n",
    "    \n",
    "    # Collect from each final folder\n",
    "    for final_folder in final_folders:\n",
    "        source_split_path = final_folder / split\n",
    "        clips_file = source_split_path / \"clips.json\"\n",
    "        \n",
    "        if clips_file.exists():\n",
    "            print(f\"Processing {final_folder.name}/{split}/clips.json\")\n",
    "            \n",
    "            with open(clips_file, 'r') as f:\n",
    "                clips = json.load(f)\n",
    "            \n",
    "            # Copy files and update paths\n",
    "            for clip in clips:\n",
    "                # Copy audio\n",
    "                if clip.get(\"audio\"):\n",
    "                    # Extract just the filename from the path\n",
    "                    audio_filename = clip[\"audio\"].split(\"/\")[-1]\n",
    "                    src_audio = source_split_path / \"audio\" / audio_filename\n",
    "                    dst_audio = output_path / split / \"audio\" / audio_filename\n",
    "                    if src_audio.exists():\n",
    "                        shutil.copy2(src_audio, dst_audio)\n",
    "                    clip[\"audio\"] = f\"data/data/{split}/audio/{audio_filename}\"\n",
    "                \n",
    "                # Copy video\n",
    "                if clip.get(\"video\"):\n",
    "                    # Extract just the filename from the path\n",
    "                    video_filename = clip[\"video\"].split(\"/\")[-1]\n",
    "                    src_video = source_split_path / \"video\" / video_filename\n",
    "                    dst_video = output_path / split / \"video\" / video_filename\n",
    "                    if src_video.exists():\n",
    "                        shutil.copy2(src_video, dst_video)\n",
    "                    clip[\"video\"] = f\"data/data/{split}/video/{video_filename}\"\n",
    "                \n",
    "                # Copy text\n",
    "                if clip.get(\"text\"):\n",
    "                    # Extract just the filename from the path\n",
    "                    text_filename = clip[\"text\"].split(\"/\")[-1]\n",
    "                    src_text = source_split_path / \"text\" / text_filename\n",
    "                    dst_text = output_path / split / \"text\" / text_filename\n",
    "                    if src_text.exists():\n",
    "                        shutil.copy2(src_text, dst_text)\n",
    "                    clip[\"text\"] = f\"data/data/{split}/text/{text_filename}\"\n",
    "                \n",
    "                combined_clips.append(clip)\n",
    "    \n",
    "    # Write combined clips.json\n",
    "    output_clips_file = output_path / split / \"clips.json\"\n",
    "    with open(output_clips_file, 'w') as f:\n",
    "        json.dump(combined_clips, f, indent=2)\n",
    "    \n",
    "    print(f\"Combined {split}: {len(combined_clips)} clips\")\n",
    "\n",
    "print(\"\\nDone! Combined data saved to data/\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dfc36f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SANITY CHECK: Clip Count Verification\n",
      "============================================================\n",
      "final_1/train: 1072 clips\n",
      "final_1/val: 233 clips\n",
      "final_1/test: 210 clips\n",
      "final_2/train: 1194 clips\n",
      "final_2/val: 308 clips\n",
      "final_2/test: 303 clips\n",
      "final_3/train: 847 clips\n",
      "final_3/val: 123 clips\n",
      "final_3/test: 265 clips\n",
      "\n",
      "------------------------------------------------------------\n",
      "Combined counts:\n",
      "------------------------------------------------------------\n",
      "data/data/train: 3113 clips\n",
      "data/data/val: 664 clips\n",
      "data/data/test: 778 clips\n",
      "\n",
      "------------------------------------------------------------\n",
      "Verification:\n",
      "------------------------------------------------------------\n",
      "train  - Expected:   3113 | Actual:   3113 | ‚úì\n",
      "val    - Expected:    664 | Actual:    664 | ‚úì\n",
      "test   - Expected:    778 | Actual:    778 | ‚úì\n",
      "\n",
      "============================================================\n",
      "‚úì All counts match! Data combination successful!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4dc37994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported torchaudio and related libraries\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Import required libraries for spectrogram conversion using torchaudio\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "print(\"Imported torchaudio and related libraries\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "57d95bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to convert WAV to mel-spectrogram JPG using torchaudio\n",
    "def wav_to_melspectrogram_jpg(wav_path, jpg_path, sr=22050, n_mels=128, n_fft=2048, hop_length=512):\n",
    "    \"\"\"\n",
    "    Convert a WAV file to a mel-spectrogram and save as JPG using torchaudio.\n",
    "    \n",
    "    Args:\n",
    "        wav_path: Path to input WAV file\n",
    "        jpg_path: Path to output JPG file\n",
    "        sr: Sample rate\n",
    "        n_mels: Number of mel bands\n",
    "        n_fft: FFT window size\n",
    "        hop_length: Number of samples between successive frames\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load audio file\n",
    "        waveform, sample_rate = torchaudio.load(wav_path)\n",
    "        \n",
    "        # Resample if necessary\n",
    "        if sample_rate != sr:\n",
    "            resampler = T.Resample(sample_rate, sr)\n",
    "            waveform = resampler(waveform)\n",
    "        \n",
    "        # Convert to mono if stereo\n",
    "        if waveform.shape[0] > 1:\n",
    "            waveform = torch.mean(waveform, dim=0, keepdim=True)\n",
    "        \n",
    "        # Create mel-spectrogram transform\n",
    "        mel_spectrogram = T.MelSpectrogram(\n",
    "            sample_rate=sr,\n",
    "            n_mels=n_mels,\n",
    "            n_fft=n_fft,\n",
    "            hop_length=hop_length\n",
    "        )\n",
    "        \n",
    "        # Compute mel-spectrogram\n",
    "        mel_spec = mel_spectrogram(waveform)\n",
    "        \n",
    "        # Convert to dB scale\n",
    "        mel_spec_db = T.AmplitudeToDB()(mel_spec)\n",
    "        \n",
    "        # Remove batch dimension and convert to numpy\n",
    "        mel_spec_np = mel_spec_db.squeeze().numpy()\n",
    "        \n",
    "        # Create figure and plot spectrogram\n",
    "        fig, ax = plt.subplots(figsize=(10, 4))\n",
    "        im = ax.imshow(mel_spec_np, aspect='auto', origin='lower', cmap='viridis')\n",
    "        ax.set_ylabel('Mel Frequency Bin')\n",
    "        ax.set_xlabel('Time Frame')\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save as JPG\n",
    "        plt.savefig(jpg_path, format='jpg', bbox_inches='tight', pad_inches=0, dpi=100)\n",
    "        plt.close()\n",
    "        \n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting {wav_path}: {str(e)}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7d5155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch convert all WAV files to mel-spectrograms for all splits\n",
    "print(\"=\" * 60)\n",
    "print(\"Converting all WAV files to mel-spectrograms...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    clips_file = output_path / split / \"clips.json\"\n",
    "    \n",
    "    if clips_file.exists():\n",
    "        print(f\"\\nProcessing {split} split...\")\n",
    "        \n",
    "        # Load clips\n",
    "        with open(clips_file, 'r') as f:\n",
    "            clips = json.load(f)\n",
    "        \n",
    "        # Create audio_img directory if it doesn't exist\n",
    "        audio_img_dir = output_path / split / \"audio_img\"\n",
    "        audio_img_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        converted_count = 0\n",
    "        failed_count = 0\n",
    "        \n",
    "        # Convert each audio file\n",
    "        for i, clip in enumerate(clips):\n",
    "            if clip.get(\"audio\"):\n",
    "                # Get the audio filename\n",
    "                audio_filename = clip[\"audio\"].split(\"/\")[-1]\n",
    "                audio_path = output_path / split / \"audio\" / audio_filename\n",
    "                \n",
    "                # Create spectrogram path\n",
    "                spectrogram_filename = audio_filename.replace(\".wav\", \".jpg\")\n",
    "                spectrogram_path = audio_img_dir / spectrogram_filename\n",
    "                \n",
    "                # Convert to spectrogram\n",
    "                if audio_path.exists():\n",
    "                    success = wav_to_melspectrogram_jpg(str(audio_path), str(spectrogram_path))\n",
    "                    if success:\n",
    "                        # Add audio_img field to clip\n",
    "                        clip[\"audio_img\"] = f\"data/data/{split}/audio_img/{spectrogram_filename}\"\n",
    "                        converted_count += 1\n",
    "                        if (i + 1) % 50 == 0:\n",
    "                            print(f\"  Converted {i + 1}/{len(clips)} clips...\")\n",
    "                    else:\n",
    "                        failed_count += 1\n",
    "                else:\n",
    "                    print(f\"  Audio file not found: {audio_path}\")\n",
    "                    failed_count += 1\n",
    "        \n",
    "        # Write updated clips.json\n",
    "        with open(clips_file, 'w') as f:\n",
    "            json.dump(clips, f, indent=2)\n",
    "        \n",
    "        print(f\"  ‚úì {split}: {converted_count} converted, {failed_count} failed\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"‚úì Spectrogram conversion complete!\")\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "33b4ee05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "VERIFICATION: Spectrogram Conversion Complete\n",
      "============================================================\n",
      "\n",
      "TRAIN:\n",
      "  JPG files created: 3111\n",
      "  Clips with audio_img field: 3111/3111\n",
      "\n",
      "VAL:\n",
      "  JPG files created: 664\n",
      "  Clips with audio_img field: 664/664\n",
      "\n",
      "TEST:\n",
      "  JPG files created: 777\n",
      "  Clips with audio_img field: 777/777\n",
      "\n",
      "------------------------------------------------------------\n",
      "Sample clip (first clip of train split):\n",
      "------------------------------------------------------------\n",
      "{\n",
      "  \"game_id\": \"20160305_1800_Manchester_City_4_0_Aston_Villa\",\n",
      "  \"original_game_name\": \"2016-03-05 - 18-00 Manchester City 4 - 0 Aston Villa\",\n",
      "  \"clip_name\": \"20160305_1800_Manchester_City_4_0_Aston_Villa_half2_clip_0345\",\n",
      "  \"half\": 2,\n",
      "  \"start_ms\": 8000,\n",
      "  \"end_ms\": 16000,\n",
      "  \"highlight\": 0,\n",
      "  \"video\": \"data/data/train/video/20160305_1800_Manchester_City_4_0_Aston_Villa_half2_clip_0345.mkv\",\n",
      "  \"audio\": \"data/data/train/audio/20160305_1800_Manchester_City_4_0_Aston_Villa_half2_clip_0345.wav\",\n",
      "  \"text\": \"data/data/train/text/20160305_1800_Manchester_City_4_0_Aston_Villa_half2_clip_0345.txt\",\n",
      "  \"audio_img\": \"data/data/train/audio_img/20160305_1800_Manchester_City_4_0_Aston_Villa_half2_clip_0345.jpg\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Verify spectrogram conversion and updated clips.json\n",
    "print(\"=\" * 60)\n",
    "print(\"VERIFICATION: Spectrogram Conversion Complete\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    audio_img_dir = output_path / split / \"audio_img\"\n",
    "    jpg_files = list(audio_img_dir.glob(\"*.jpg\")) if audio_img_dir.exists() else []\n",
    "    \n",
    "    clips_file = output_path / split / \"clips.json\"\n",
    "    with open(clips_file, 'r') as f:\n",
    "        clips = json.load(f)\n",
    "    \n",
    "    clips_with_audio_img = sum(1 for clip in clips if \"audio_img\" in clip)\n",
    "    \n",
    "    print(f\"\\n{split.upper()}:\")\n",
    "    print(f\"  JPG files created: {len(jpg_files)}\")\n",
    "    print(f\"  Clips with audio_img field: {clips_with_audio_img}/{len(clips)}\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "print(\"Sample clip (first clip of train split):\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "with open(output_path / \"train\" / \"clips.json\", 'r') as f:\n",
    "    clips = json.load(f)\n",
    "    if clips:\n",
    "        sample_clip = clips[0]\n",
    "        print(json.dumps(sample_clip, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a4c7d80f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Finding missing spectrogram conversions...\n",
      "============================================================\n",
      "\n",
      "TRAIN split:\n",
      "  ‚úì All clips have audio_img field\n",
      "\n",
      "VAL split:\n",
      "  ‚úì All clips have audio_img field\n",
      "\n",
      "TEST split:\n",
      "  ‚úì All clips have audio_img field\n",
      "\n",
      "============================================================\n",
      "SUMMARY: 0 missing spectrogram conversions\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Find which audio files are missing spectrograms\n",
    "print(\"=\" * 60)\n",
    "print(\"Finding missing spectrogram conversions...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "missing_files = []\n",
    "\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    clips_file = output_path / split / \"clips.json\"\n",
    "    audio_img_dir = output_path / split / \"audio_img\"\n",
    "    \n",
    "    if clips_file.exists():\n",
    "        # Load clips\n",
    "        with open(clips_file, 'r') as f:\n",
    "            clips = json.load(f)\n",
    "        \n",
    "        # Check which clips are missing audio_img\n",
    "        print(f\"\\n{split.upper()} split:\")\n",
    "        split_missing = []\n",
    "        \n",
    "        for clip in clips:\n",
    "            if clip.get(\"audio\") and \"audio_img\" not in clip:\n",
    "                audio_filename = clip[\"audio\"].split(\"/\")[-1]\n",
    "                audio_path = output_path / split / \"audio\" / audio_filename\n",
    "                \n",
    "                split_missing.append({\n",
    "                    \"clip_name\": clip.get(\"clip_name\"),\n",
    "                    \"audio_file\": audio_filename,\n",
    "                    \"audio_exists\": audio_path.exists(),\n",
    "                    \"full_path\": str(audio_path)\n",
    "                })\n",
    "        \n",
    "        if split_missing:\n",
    "            print(f\"  Found {len(split_missing)} clips without audio_img field:\")\n",
    "            for item in split_missing:\n",
    "                print(f\"    - {item['clip_name']}\")\n",
    "                print(f\"      Audio file: {item['audio_file']}\")\n",
    "                print(f\"      File exists: {item['audio_exists']}\")\n",
    "                print(f\"      Path: {item['full_path']}\\n\")\n",
    "            missing_files.extend(split_missing)\n",
    "        else:\n",
    "            print(f\"  ‚úì All clips have audio_img field\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(f\"SUMMARY: {len(missing_files)} missing spectrogram conversions\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if missing_files:\n",
    "    print(\"\\nDetailed list of missing files:\")\n",
    "    for i, item in enumerate(missing_files, 1):\n",
    "        print(f\"\\n{i}. Clip: {item['clip_name']}\")\n",
    "        print(f\"   Audio file exists: {item['audio_exists']}\")\n",
    "        if not item['audio_exists']:\n",
    "            print(f\"   ‚ö†Ô∏è  Audio file not found at: {item['full_path']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "56d67e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Retrying conversion of missing audio files...\n",
      "============================================================\n",
      "\n",
      "TRAIN split:\n",
      "  Retrying: 20151107_2030_Stoke_City_1_0_Chelsea_half1_clip_0024\n",
      "Error converting c:\\Users\\golde\\Documents\\UMD\\CMSC498K - Multimodal Deep Learning\\FinalProject\\data\\data\\train\\audio\\20151107_2030_Stoke_City_1_0_Chelsea_half1_clip_0024.wav: cannot reshape tensor of 0 elements into shape [-1, 0] because the unspecified dimension size -1 can be any value and is ambiguous\n",
      "    ‚úó Conversion failed\n",
      "  Retrying: 20151107_2030_Stoke_City_1_0_Chelsea_half1_clip_0021\n",
      "Error converting c:\\Users\\golde\\Documents\\UMD\\CMSC498K - Multimodal Deep Learning\\FinalProject\\data\\data\\train\\audio\\20151107_2030_Stoke_City_1_0_Chelsea_half1_clip_0021.wav: cannot reshape tensor of 0 elements into shape [-1, 0] because the unspecified dimension size -1 can be any value and is ambiguous\n",
      "    ‚úó Conversion failed\n",
      "  Retry results: 0 converted, 2 failed\n",
      "\n",
      "VAL split:\n",
      "  Retry results: 0 converted, 0 failed\n",
      "\n",
      "TEST split:\n",
      "  Retrying: 20150926_1700_Manchester_United_3_0_Sunderland_half2_clip_0710\n",
      "Error converting c:\\Users\\golde\\Documents\\UMD\\CMSC498K - Multimodal Deep Learning\\FinalProject\\data\\data\\test\\audio\\20150926_1700_Manchester_United_3_0_Sunderland_half2_clip_0710.wav: Argument #4: Padding size should be less than the corresponding input dimension, but got: padding (1024, 1024) at dimension 2 of input [1, 1, 155]\n",
      "    ‚úó Conversion failed\n",
      "  Retry results: 0 converted, 1 failed\n",
      "\n",
      "============================================================\n",
      "Retry Summary: 0 successfully converted, 3 still failing\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\golde\\Documents\\UMD\\CMSC498K - Multimodal Deep Learning\\.venv\\lib\\site-packages\\torchaudio\\_backend\\utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Retry converting missing audio files\n",
    "print(\"=\" * 60)\n",
    "print(\"Retrying conversion of missing audio files...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "retry_count = 0\n",
    "retry_failed = 0\n",
    "\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    clips_file = output_path / split / \"clips.json\"\n",
    "    \n",
    "    if clips_file.exists():\n",
    "        # Load clips\n",
    "        with open(clips_file, 'r') as f:\n",
    "            clips = json.load(f)\n",
    "        \n",
    "        audio_img_dir = output_path / split / \"audio_img\"\n",
    "        audio_img_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        print(f\"\\n{split.upper()} split:\")\n",
    "        split_retry_count = 0\n",
    "        split_retry_failed = 0\n",
    "        \n",
    "        # Find and retry missing conversions\n",
    "        for clip in clips:\n",
    "            if clip.get(\"audio\") and \"audio_img\" not in clip:\n",
    "                audio_filename = clip[\"audio\"].split(\"/\")[-1]\n",
    "                audio_path = output_path / split / \"audio\" / audio_filename\n",
    "                \n",
    "                if audio_path.exists():\n",
    "                    print(f\"  Retrying: {clip.get('clip_name')}\")\n",
    "                    \n",
    "                    # Create spectrogram path\n",
    "                    spectrogram_filename = audio_filename.replace(\".wav\", \".jpg\")\n",
    "                    spectrogram_path = audio_img_dir / spectrogram_filename\n",
    "                    \n",
    "                    # Try conversion\n",
    "                    try:\n",
    "                        success = wav_to_melspectrogram_jpg(str(audio_path), str(spectrogram_path))\n",
    "                        if success:\n",
    "                            # Add audio_img field to clip\n",
    "                            clip[\"audio_img\"] = f\"data/data/{split}/audio_img/{spectrogram_filename}\"\n",
    "                            split_retry_count += 1\n",
    "                            print(f\"    ‚úì Successfully converted\")\n",
    "                        else:\n",
    "                            split_retry_failed += 1\n",
    "                            print(f\"    ‚úó Conversion failed\")\n",
    "                    except Exception as e:\n",
    "                        split_retry_failed += 1\n",
    "                        print(f\"    ‚úó Error: {str(e)}\")\n",
    "                else:\n",
    "                    split_retry_failed += 1\n",
    "                    print(f\"  ‚úó Audio file not found: {audio_filename}\")\n",
    "        \n",
    "        # Write updated clips.json\n",
    "        with open(clips_file, 'w') as f:\n",
    "            json.dump(clips, f, indent=2)\n",
    "        \n",
    "        print(f\"  Retry results: {split_retry_count} converted, {split_retry_failed} failed\")\n",
    "        retry_count += split_retry_count\n",
    "        retry_failed += split_retry_failed\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(f\"Retry Summary: {retry_count} successfully converted, {retry_failed} still failing\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "493baef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "FINAL VERIFICATION: After Retry Conversion\n",
      "============================================================\n",
      "\n",
      "TRAIN:\n",
      "  Total clips: 3113\n",
      "  JPG files: 3111\n",
      "  Clips with audio_img: 3111\n",
      "  ‚ö†Ô∏è  Still missing: 2\n",
      "     - 20151107_2030_Stoke_City_1_0_Chelsea_half1_clip_0024: data/data/train/audio/20151107_2030_Stoke_City_1_0_Chelsea_half1_clip_0024.wav\n",
      "     - 20151107_2030_Stoke_City_1_0_Chelsea_half1_clip_0021: data/data/train/audio/20151107_2030_Stoke_City_1_0_Chelsea_half1_clip_0021.wav\n",
      "\n",
      "VAL:\n",
      "  Total clips: 664\n",
      "  JPG files: 664\n",
      "  Clips with audio_img: 664\n",
      "  ‚úì All clips have spectrograms!\n",
      "\n",
      "TEST:\n",
      "  Total clips: 778\n",
      "  JPG files: 777\n",
      "  Clips with audio_img: 777\n",
      "  ‚ö†Ô∏è  Still missing: 1\n",
      "     - 20150926_1700_Manchester_United_3_0_Sunderland_half2_clip_0710: data/data/test/audio/20150926_1700_Manchester_United_3_0_Sunderland_half2_clip_0710.wav\n",
      "\n",
      "============================================================\n",
      "OVERALL: 4552/4555 clips with spectrograms\n",
      "‚ö†Ô∏è  Missing: 3\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Final verification after retry\n",
    "print(\"=\" * 60)\n",
    "print(\"FINAL VERIFICATION: After Retry Conversion\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "total_clips = 0\n",
    "total_with_audio_img = 0\n",
    "\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    clips_file = output_path / split / \"clips.json\"\n",
    "    \n",
    "    if clips_file.exists():\n",
    "        with open(clips_file, 'r') as f:\n",
    "            clips = json.load(f)\n",
    "        \n",
    "        audio_img_dir = output_path / split / \"audio_img\"\n",
    "        jpg_files = list(audio_img_dir.glob(\"*.jpg\")) if audio_img_dir.exists() else []\n",
    "        \n",
    "        clips_with_audio_img = sum(1 for clip in clips if \"audio_img\" in clip)\n",
    "        total_clips += len(clips)\n",
    "        total_with_audio_img += clips_with_audio_img\n",
    "        \n",
    "        print(f\"\\n{split.upper()}:\")\n",
    "        print(f\"  Total clips: {len(clips)}\")\n",
    "        print(f\"  JPG files: {len(jpg_files)}\")\n",
    "        print(f\"  Clips with audio_img: {clips_with_audio_img}\")\n",
    "        \n",
    "        # Still missing?\n",
    "        still_missing = len(clips) - clips_with_audio_img\n",
    "        if still_missing > 0:\n",
    "            print(f\"  ‚ö†Ô∏è  Still missing: {still_missing}\")\n",
    "            \n",
    "            # List the still-missing ones\n",
    "            for clip in clips:\n",
    "                if clip.get(\"audio\") and \"audio_img\" not in clip:\n",
    "                    print(f\"     - {clip.get('clip_name')}: {clip.get('audio')}\")\n",
    "        else:\n",
    "            print(f\"  ‚úì All clips have spectrograms!\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(f\"OVERALL: {total_with_audio_img}/{total_clips} clips with spectrograms\")\n",
    "if total_with_audio_img == total_clips:\n",
    "    print(\"‚úì ALL CONVERSIONS COMPLETE!\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è  Missing: {total_clips - total_with_audio_img}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2f42522c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ANALYZING CORRUPTED AUDIO FILES AND NEIGHBORS\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "SPLIT: TRAIN | CLIP: 20151107_2030_Stoke_City_1_0_Chelsea_half1_clip_0024\n",
      "================================================================================\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Clip #2597: 20151107_2030_Stoke_City_1_0_Chelsea_half2_clip_0454\n",
      "Audio: data/data/train/audio/20151107_2030_Stoke_City_1_0_Chelsea_half2_clip_0454.wav\n",
      "Has audio_img: True\n",
      "--------------------------------------------------------------------------------\n",
      "Sample rate: 16000 Hz\n",
      "Channels: 1\n",
      "Samples: 128000\n",
      "Duration: 8000.00 ms\n",
      "Min value: -0.2256\n",
      "Max value: 0.2514\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Clip #2598: 20151107_2030_Stoke_City_1_0_Chelsea_half1_clip_0024\n",
      "‚ö†Ô∏è  CORRUPTED FILE\n",
      "Audio: data/data/train/audio/20151107_2030_Stoke_City_1_0_Chelsea_half1_clip_0024.wav\n",
      "Has audio_img: False\n",
      "--------------------------------------------------------------------------------\n",
      "Sample rate: 16000 Hz\n",
      "Channels: 1\n",
      "Samples: 0\n",
      "Duration: 0.00 ms\n",
      "‚ùå Error loading audio: min(): Expected reduction dim to be specified for input.numel() == 0. Specify the reduction dim with the 'dim' argument.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Clip #2599: 20151107_2030_Stoke_City_1_0_Chelsea_half1_clip_0127\n",
      "Audio: data/data/train/audio/20151107_2030_Stoke_City_1_0_Chelsea_half1_clip_0127.wav\n",
      "Has audio_img: True\n",
      "--------------------------------------------------------------------------------\n",
      "Sample rate: 16000 Hz\n",
      "Channels: 1\n",
      "Samples: 128000\n",
      "Duration: 8000.00 ms\n",
      "Min value: -0.2985\n",
      "Max value: 0.4032\n",
      "\n",
      "================================================================================\n",
      "SPLIT: TRAIN | CLIP: 20151107_2030_Stoke_City_1_0_Chelsea_half1_clip_0021\n",
      "================================================================================\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Clip #2611: 20151107_2030_Stoke_City_1_0_Chelsea_half1_clip_0195\n",
      "Audio: data/data/train/audio/20151107_2030_Stoke_City_1_0_Chelsea_half1_clip_0195.wav\n",
      "Has audio_img: True\n",
      "--------------------------------------------------------------------------------\n",
      "Sample rate: 16000 Hz\n",
      "Channels: 1\n",
      "Samples: 128000\n",
      "Duration: 8000.00 ms\n",
      "Min value: -0.3702\n",
      "Max value: 0.3370\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Clip #2612: 20151107_2030_Stoke_City_1_0_Chelsea_half1_clip_0021\n",
      "‚ö†Ô∏è  CORRUPTED FILE\n",
      "Audio: data/data/train/audio/20151107_2030_Stoke_City_1_0_Chelsea_half1_clip_0021.wav\n",
      "Has audio_img: False\n",
      "--------------------------------------------------------------------------------\n",
      "Sample rate: 16000 Hz\n",
      "Channels: 1\n",
      "Samples: 0\n",
      "Duration: 0.00 ms\n",
      "‚ùå Error loading audio: min(): Expected reduction dim to be specified for input.numel() == 0. Specify the reduction dim with the 'dim' argument.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Clip #2613: 20151107_2030_Stoke_City_1_0_Chelsea_half2_clip_0586\n",
      "Audio: data/data/train/audio/20151107_2030_Stoke_City_1_0_Chelsea_half2_clip_0586.wav\n",
      "Has audio_img: True\n",
      "--------------------------------------------------------------------------------\n",
      "Sample rate: 16000 Hz\n",
      "Channels: 1\n",
      "Samples: 128000\n",
      "Duration: 8000.00 ms\n",
      "Min value: -0.2790\n",
      "Max value: 0.2689\n",
      "\n",
      "================================================================================\n",
      "SPLIT: TEST | CLIP: 20150926_1700_Manchester_United_3_0_Sunderland_half2_clip_0710\n",
      "================================================================================\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Clip #381: 20150926_1700_Manchester_United_3_0_Sunderland_half2_clip_0584\n",
      "Audio: data/data/test/audio/20150926_1700_Manchester_United_3_0_Sunderland_half2_clip_0584.wav\n",
      "Has audio_img: True\n",
      "--------------------------------------------------------------------------------\n",
      "Sample rate: 16000 Hz\n",
      "Channels: 1\n",
      "Samples: 128000\n",
      "Duration: 8000.00 ms\n",
      "Min value: -0.3066\n",
      "Max value: 0.3231\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Clip #382: 20150926_1700_Manchester_United_3_0_Sunderland_half2_clip_0710\n",
      "‚ö†Ô∏è  CORRUPTED FILE\n",
      "Audio: data/data/test/audio/20150926_1700_Manchester_United_3_0_Sunderland_half2_clip_0710.wav\n",
      "Has audio_img: False\n",
      "--------------------------------------------------------------------------------\n",
      "Sample rate: 16000 Hz\n",
      "Channels: 1\n",
      "Samples: 112\n",
      "Duration: 7.00 ms\n",
      "Min value: -0.0958\n",
      "Max value: 0.0797\n",
      "\n",
      "üìä Audio Player:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" >\n",
       "                    <source src=\"data:audio/wav;base64,UklGRiYBAABXQVZFZm10IBAAAAABAAEAgD4AAAB9AAACABAATElTVBoAAABJTkZPSVNGVA4AAABMYXZmNTguNzYuMTAwAGRhdGHgAAAASQBrAmMFmgfhCH0J9wgTB4QD6/5h+833QvVW9db2XfiQ+mX84Psh++X66vrv+1f+YANrCDUKlwltBxQFfgNVAowCpgPmA0cDMwIKArgBjf+d++/3UfW980H1zvm6/s4CSAViBioG/QSJA0ECIwFtAP3/tf+B/2//cP88/9X+f/5Z/lb+qP4//9L/RwCrAMwAnQB3AF8AhACWAHoAbABWADcADwDW/7H/pf97/1v/nf8KAFcAhwCfAHEAEQDW/6f/kf+0/63/ov+//9b/BQANAC8ATwBbAHQAbQA3AOn/7v8=\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Clip #383: 20150926_1700_Manchester_United_3_0_Sunderland_half1_clip_0112\n",
      "Audio: data/data/test/audio/20150926_1700_Manchester_United_3_0_Sunderland_half1_clip_0112.wav\n",
      "Has audio_img: True\n",
      "--------------------------------------------------------------------------------\n",
      "Sample rate: 16000 Hz\n",
      "Channels: 1\n",
      "Samples: 128000\n",
      "Duration: 8000.00 ms\n",
      "Min value: -0.3920\n",
      "Max value: 0.3854\n",
      "\n",
      "================================================================================\n",
      "END OF ANALYSIS\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Inspect the 3 corrupted audio files and their neighbors\n",
    "from IPython.display import Audio, display\n",
    "import soundfile as sf\n",
    "\n",
    "corrupted_files = [\n",
    "    (\"train\", \"20151107_2030_Stoke_City_1_0_Chelsea_half1_clip_0024\"),\n",
    "    (\"train\", \"20151107_2030_Stoke_City_1_0_Chelsea_half1_clip_0021\"),\n",
    "    (\"test\", \"20150926_1700_Manchester_United_3_0_Sunderland_half2_clip_0710\")\n",
    "]\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ANALYZING CORRUPTED AUDIO FILES AND NEIGHBORS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for split, clip_name in corrupted_files:\n",
    "    print(f\"\\n{'=' * 80}\")\n",
    "    print(f\"SPLIT: {split.upper()} | CLIP: {clip_name}\")\n",
    "    print('=' * 80)\n",
    "    \n",
    "    # Load clips.json\n",
    "    clips_file = output_path / split / \"clips.json\"\n",
    "    with open(clips_file, 'r') as f:\n",
    "        clips = json.load(f)\n",
    "    \n",
    "    # Find the clip index\n",
    "    clip_idx = None\n",
    "    for idx, clip in enumerate(clips):\n",
    "        if clip.get(\"clip_name\") == clip_name:\n",
    "            clip_idx = idx\n",
    "            break\n",
    "    \n",
    "    if clip_idx is not None:\n",
    "        # Get clips before, current, and after\n",
    "        start_idx = max(0, clip_idx - 1)\n",
    "        end_idx = min(len(clips), clip_idx + 2)\n",
    "        \n",
    "        for idx in range(start_idx, end_idx):\n",
    "            current_clip = clips[idx]\n",
    "            is_corrupted = current_clip.get(\"clip_name\") == clip_name\n",
    "            \n",
    "            print(f\"\\n{'-' * 80}\")\n",
    "            print(f\"Clip #{idx}: {current_clip.get('clip_name')}\")\n",
    "            if is_corrupted:\n",
    "                print(\"‚ö†Ô∏è  CORRUPTED FILE\")\n",
    "            print(f\"Audio: {current_clip.get('audio')}\")\n",
    "            print(f\"Has audio_img: {'audio_img' in current_clip}\")\n",
    "            print(f\"-\" * 80)\n",
    "            \n",
    "            # Try to load and display audio info\n",
    "            audio_filename = current_clip.get(\"audio\", \"\").split(\"/\")[-1]\n",
    "            audio_path = output_path / split / \"audio\" / audio_filename\n",
    "            \n",
    "            if audio_path.exists():\n",
    "                try:\n",
    "                    # Get audio info\n",
    "                    waveform, sample_rate = torchaudio.load(str(audio_path))\n",
    "                    duration_ms = (waveform.shape[1] / sample_rate) * 1000\n",
    "                    \n",
    "                    print(f\"Sample rate: {sample_rate} Hz\")\n",
    "                    print(f\"Channels: {waveform.shape[0]}\")\n",
    "                    print(f\"Samples: {waveform.shape[1]}\")\n",
    "                    print(f\"Duration: {duration_ms:.2f} ms\")\n",
    "                    print(f\"Min value: {waveform.min():.4f}\")\n",
    "                    print(f\"Max value: {waveform.max():.4f}\")\n",
    "                    \n",
    "                    if is_corrupted:\n",
    "                        print(\"\\nüìä Audio Player:\")\n",
    "                        display(Audio(str(audio_path)))\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"‚ùå Error loading audio: {str(e)}\")\n",
    "            else:\n",
    "                print(f\"‚ùå Audio file not found: {audio_path}\")\n",
    "\n",
    "print(f\"\\n{'=' * 80}\")\n",
    "print(\"END OF ANALYSIS\")\n",
    "print('=' * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b2e3bd10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Removing corrupted clips from data...\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing TRAIN: 20151107_2030_Stoke_City_1_0_Chelsea_half1_clip_0024\n",
      "================================================================================\n",
      "‚úì Found clip in clips.json\n",
      "  ‚úì Deleted audio: 20151107_2030_Stoke_City_1_0_Chelsea_half1_clip_0024.wav\n",
      "  ‚úì Deleted video: 20151107_2030_Stoke_City_1_0_Chelsea_half1_clip_0024.mkv\n",
      "  ‚úì Deleted text: 20151107_2030_Stoke_City_1_0_Chelsea_half1_clip_0024.txt\n",
      "‚úì Updated clips.json (3112 clips remaining)\n",
      "\n",
      "================================================================================\n",
      "Processing TRAIN: 20151107_2030_Stoke_City_1_0_Chelsea_half1_clip_0021\n",
      "================================================================================\n",
      "‚úì Found clip in clips.json\n",
      "  ‚úì Deleted audio: 20151107_2030_Stoke_City_1_0_Chelsea_half1_clip_0021.wav\n",
      "  ‚úì Deleted video: 20151107_2030_Stoke_City_1_0_Chelsea_half1_clip_0021.mkv\n",
      "  ‚úì Deleted text: 20151107_2030_Stoke_City_1_0_Chelsea_half1_clip_0021.txt\n",
      "‚úì Updated clips.json (3111 clips remaining)\n",
      "\n",
      "================================================================================\n",
      "Processing TEST: 20150926_1700_Manchester_United_3_0_Sunderland_half2_clip_0710\n",
      "================================================================================\n",
      "‚úì Found clip in clips.json\n",
      "  ‚úì Deleted audio: 20150926_1700_Manchester_United_3_0_Sunderland_half2_clip_0710.wav\n",
      "  ‚úì Deleted video: 20150926_1700_Manchester_United_3_0_Sunderland_half2_clip_0710.mkv\n",
      "  ‚úì Deleted text: 20150926_1700_Manchester_United_3_0_Sunderland_half2_clip_0710.txt\n",
      "‚úì Updated clips.json (777 clips remaining)\n",
      "\n",
      "================================================================================\n",
      "SUMMARY: 3/3 corrupted clips removed\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Remove the 3 corrupted audio clips from all data and update clips.json\n",
    "print(\"=\" * 80)\n",
    "print(\"Removing corrupted clips from data...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "corrupted_clips_to_remove = [\n",
    "    (\"train\", \"20151107_2030_Stoke_City_1_0_Chelsea_half1_clip_0024\"),\n",
    "    (\"train\", \"20151107_2030_Stoke_City_1_0_Chelsea_half1_clip_0021\"),\n",
    "    (\"test\", \"20150926_1700_Manchester_United_3_0_Sunderland_half2_clip_0710\")\n",
    "]\n",
    "\n",
    "total_removed = 0\n",
    "\n",
    "for split, clip_name_to_remove in corrupted_clips_to_remove:\n",
    "    print(f\"\\n{'=' * 80}\")\n",
    "    print(f\"Processing {split.upper()}: {clip_name_to_remove}\")\n",
    "    print('=' * 80)\n",
    "    \n",
    "    # Load clips.json\n",
    "    clips_file = output_path / split / \"clips.json\"\n",
    "    with open(clips_file, 'r') as f:\n",
    "        clips = json.load(f)\n",
    "    \n",
    "    # Find and remove the clip\n",
    "    clip_to_remove = None\n",
    "    for clip in clips:\n",
    "        if clip.get(\"clip_name\") == clip_name_to_remove:\n",
    "            clip_to_remove = clip\n",
    "            clips.remove(clip)\n",
    "            break\n",
    "    \n",
    "    if clip_to_remove:\n",
    "        print(f\"‚úì Found clip in clips.json\")\n",
    "        \n",
    "        # Delete associated files\n",
    "        files_to_delete = {\n",
    "            \"audio\": clip_to_remove.get(\"audio\"),\n",
    "            \"video\": clip_to_remove.get(\"video\"),\n",
    "            \"text\": clip_to_remove.get(\"text\"),\n",
    "            \"audio_img\": clip_to_remove.get(\"audio_img\")\n",
    "        }\n",
    "        \n",
    "        for file_type, file_path in files_to_delete.items():\n",
    "            if file_path:\n",
    "                # Extract filename from path\n",
    "                filename = file_path.split(\"/\")[-1]\n",
    "                full_path = output_path / split / file_type / filename\n",
    "                \n",
    "                if full_path.exists():\n",
    "                    full_path.unlink()  # Delete file\n",
    "                    print(f\"  ‚úì Deleted {file_type}: {filename}\")\n",
    "                else:\n",
    "                    print(f\"  ‚ö†Ô∏è  {file_type} file not found: {filename}\")\n",
    "        \n",
    "        # Write updated clips.json\n",
    "        with open(clips_file, 'w') as f:\n",
    "            json.dump(clips, f, indent=2)\n",
    "        \n",
    "        print(f\"‚úì Updated clips.json ({len(clips)} clips remaining)\")\n",
    "        total_removed += 1\n",
    "    else:\n",
    "        print(f\"‚ùå Clip not found in clips.json\")\n",
    "\n",
    "print(f\"\\n{'=' * 80}\")\n",
    "print(f\"SUMMARY: {total_removed}/3 corrupted clips removed\")\n",
    "print('=' * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9574f52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
